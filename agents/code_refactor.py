import os
import json
import openai
import requests
from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton
from datetime import datetime
from dotenv import load_dotenv
import subprocess  # –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ remote_agent / splitter
import sys
import os

sys.path.append(os.path.abspath("."))


load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

openai.api_key = OPENAI_API_KEY

FILE_MAP_PATH = "logs/saci_file_map.json"
PATCH_DIR = "patches"

CHUNKS_PATH = "logs/saci_code_chunks.json"


def safe_patch_slice(text, max_chars=2500):
    lines = text.splitlines(keepends=True)
    result = ""
    total = 0
    for line in lines:
        if total + len(line) > max_chars:
            break
        result += line
        total += len(line)
    return result


def run_multi_pass_refactor():
    subprocess.run(["python", "saci_remote_agent.py"])

    with open("logs/saci_code_chunks.json", "r", encoding="utf-8") as f:
        chunks = json.load(f)

    batches = split_chunks_into_batches(chunks, batch_size=10)
    combined_diff = ""
    print(f"üîÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(batches)} batch'–µ–π...")

    for i, batch in enumerate(batches):
        print(f"üì¶ Batch {i+1}/{len(batches)}")
        diff = request_gpt_patch(batch)
        combined_diff += diff + "\n\n"

    # Save combined patch
    ts = datetime.now().strftime("%Y-%m-%d_%H-%M")
    filename = f"auto_gpt_patch_{ts}_combined.patch"
    path = os.path.join("patches", filename)
    with open(path, "w", encoding="utf-8") as f:
        f.write(combined_diff)

    print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –ø–∞—Ç—á —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}")
    send_patch_with_buttons(filename)


def split_chunks_into_batches(chunks: dict, batch_size: int = 25):
    keys = list(chunks.keys())
    return [
        dict((k, chunks[k]) for k in keys[i : i + batch_size])
        for i in range(0, len(keys), batch_size)
    ]


def generate_all_reviews_markdown(patch_name):
    agents = {
        "architect": "üß† Architect",
        "developer": "üë®‚Äçüíª Developer",
        "tester": "üß™ Tester",
        "strategist": "üéØ Strategist",
    }

    md = f"# üîç Patch Review ‚Äî `{patch_name}`\n\n---\n"

    for agent_key, emoji_title in agents.items():
        review = generate_patch_review(patch_name, agent_key)
        md += f"\n## {emoji_title}\n\n{review}\n\n---\n"

    os.makedirs("logs/patch_reviews", exist_ok=True)
    path = f"logs/patch_reviews/{patch_name}.md"
    with open(path, "w", encoding="utf-8") as f:
        f.write(md)

    return path


def send_review_markdown_to_telegram(patch_name):
    path = f"logs/patch_reviews/{patch_name}.md"
    if not os.path.exists(path):
        return

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendDocument"
    with open(path, "rb") as doc:
        files = {"document": doc}
        data = {
            "chat_id": CHAT_ID,
            "caption": f"üìÑ –û–±—â–µ–µ —Ä–µ–≤—å—é –æ—Ç –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ `{patch_name}`",
            "parse_mode": "Markdown",
        }
        requests.post(url, files=files, data=data)


def generate_patch_review(patch_name, agent="architect"):
    patch_path = None
    for ext in [".patch", ".diff"]:
        path = f"patches/{patch_name}{ext}"
        if os.path.exists(path):
            patch_path = path
            break

    if not patch_path:
        return "‚ùå Patch –Ω–µ –Ω–∞–π–¥–µ–Ω."

    with open(patch_path, "r", encoding="utf-8") as f:
        patch_text = f.read()

    persona = {
        "architect": "–¢—ã ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π AI, –æ—Ü–µ–Ω–∏–≤–∞–µ—à—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏.",
        "developer": "–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π Python-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ SACI.",
        "tester": "–¢—ã ‚Äî AI-—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫, –∏—â–µ—à—å —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞.",
        "strategist": "–¢—ã ‚Äî AI-—Å—Ç—Ä–∞—Ç–µ–≥, —Å–º–æ—Ç—Ä–∏—à—å –Ω–∞ –ø–æ–ª—å–∑—É –≤ –±—É–¥—É—â–µ–º.",
    }.get(agent, "–¢—ã ‚Äî AI-–ø–æ–º–æ—â–Ω–∏–∫.")

    prompt = f"""
{persona}
–î–∞–π —Ä–µ–≤—å—é –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π patch (diff):
- –ß—Ç–æ —É–ª—É—á—à–∞–µ—Ç?
- –ö–∞–∫–∏–µ –ø–ª—é—Å—ã?
- –ï—Å—Ç—å –ª–∏ —Ä–∏—Å–∫–∏?
{safe_patch_slice(patch_text)}
"""

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": persona},
            {"role": "user", "content": prompt},
        ],
        temperature=0.4,
        max_tokens=400,
    )

    return response["choices"][0]["message"]["content"].strip()


def generate_all_patch_reviews(patch_name):
    agents = ["architect", "developer", "tester", "strategist"]
    results = {}
    for agent in agents:
        review = generate_patch_review(patch_name, agent)
        results[agent] = review
    return results


def send_patch_with_reviews(filename):
    base = filename.replace(".patch", "").replace(".diff", "")
    reviews = generate_all_patch_reviews(base)

    markup = InlineKeyboardMarkup(row_width=2)
    markup.add(
        InlineKeyboardButton("üìÑ –ü—Ä–æ—Å–º–æ—Ç—Ä patch", callback_data=f"review:{base}"),
        InlineKeyboardButton("‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å", callback_data=f"apply:{base}"),
    )
    markup.row(
        InlineKeyboardButton(
            "üß† Architect", callback_data=f"view_rev:{base}:architect"
        ),
        InlineKeyboardButton(
            "üë®‚Äçüíª Developer", callback_data=f"view_rev:{base}:developer"
        ),
        InlineKeyboardButton("üß™ Tester", callback_data=f"view_rev:{base}:tester"),
        InlineKeyboardButton(
            "üéØ Strategist", callback_data=f"view_rev:{base}:strategist"
        ),
    )

    review_text = "\n".join(
        [f"*{agent.title()}*:\n{review[:200]}" for agent, review in reviews.items()]
    )

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": f"üì¶ GPT-–ø–∞—Ç—á `{filename}`\n\nüß† –†–µ–≤—å—é –∞–≥–µ–Ω—Ç–æ–≤:\n\n{review_text}\n\n–í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∏–∂–µ:",
        "reply_markup": json.dumps(markup.to_dict()),
        "parse_mode": "Markdown",
    }
    requests.post(url, json=payload)


from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton


def send_patch_with_buttons(filename):
    base = filename.replace(".diff", "").replace(".patch", "")

    markup = InlineKeyboardMarkup(row_width=2)
    markup.add(
        InlineKeyboardButton("üìÑ –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å", callback_data=f"review:{base}"),
        InlineKeyboardButton("‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å", callback_data=f"apply:{base}"),
        InlineKeyboardButton(
            "üß† Architect", callback_data=f"review_agent:{base}:architect"
        ),
        InlineKeyboardButton(
            "üë®‚Äçüíª Developer", callback_data=f"review_agent:{base}:developer"
        ),
        InlineKeyboardButton(
            "üéØ Strategist", callback_data=f"review_agent:{base}:strategist"
        ),
    )

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": f"üì¶ GPT –ø—Ä–µ–¥–ª–æ–∂–∏–ª –ø–∞—Ç—á: `{filename}`\n\nüìé –í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ:",
        "reply_markup": json.dumps(markup.to_dict()),
        "parse_mode": "Markdown",
    }

    requests.post(url, json=payload)


def load_chunks():
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî Tree-sitter
    tree_chunks_path = "logs/saci_code_chunks.json"
    if os.path.exists(tree_chunks_path):
        with open(tree_chunks_path, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        print("‚ö†Ô∏è –ß–∞–Ω–∫–∏ Tree-sitter –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞—Ä—ã–π split.")
        with open("logs/saci_file_map.json", "r", encoding="utf-8") as f:
            file_map = json.load(f)


# removed call to split_all_py_files (module was deleted)


def generate_patch_prompt(file_map):
    file_bundle = "\n\n".join(
        [
            f"### {fname}\n```python\n{content[:1500]}\n```"
            for fname, content in file_map.items()
            if fname.endswith(".py")
        ]
    )
    return f"""
–¢—ã ‚Äî AI-–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä SACI. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ unified diff (git diff).

–¢–æ–ª—å–∫–æ –æ–¥–∏–Ω diff-—Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏. –í–Ω–∏–∑—É ‚Äî –∫—Ä–∞—Ç–∫–∏–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). –ù–∏–∫–∞–∫–∏—Ö –ª–∏—à–Ω–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.

–í–æ—Ç –∫–æ–¥:
{file_bundle}
"""


def request_gpt_patch(chunks_batch):
    prompt = (
        "–¢—ã ‚Äî AI-–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä. –í–æ—Ç —á–∞–Ω–∫–∏ –∫–æ–¥–∞. –ü—Ä–µ–¥–ª–æ–∂–∏ patch –≤ —Ñ–æ—Ä–º–∞—Ç–µ unified diff:\n\n"
    )
    for name, code in chunks_batch.items():
        sliced = code[:2000]
        prompt += f"### {name} ###\n```\n{sliced}\n```\n\n"
    prompt += "\n–û—Ç–≤–µ—Ç–∏ —Ç–æ–ª—å–∫–æ git patch (unified diff), –±–µ–∑ markdown, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "–¢—ã ‚Äî AI-—Ä–µ–≤—å—é–µ—Ä. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ .diff patch."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
        max_tokens=1200,
    )
    return response.choices[0].message.content.strip()


def priority_sort(name):
    if "goal_runner" in name:
        return 1
    if "developer" in name:
        return 2
    if "tester" in name:
        return 3
    if "core/" in name:
        return 4
    return 99


def save_patch(content):
    os.makedirs(PATCH_DIR, exist_ok=True)
    ts = datetime.now().strftime("%Y-%m-%d_%H-%M")
    filename = f"auto_gpt_patch_{ts}.diff"
    path = os.path.join(PATCH_DIR, filename)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return filename, path


def is_patch_valid(content):
    return content.startswith("diff --git") and "@@" in content and "--- " in content


def repair_patch_with_gpt(content):
    print("üîß –ü–∞—Ç—á –ø–æ–≤—Ä–µ–∂–¥—ë–Ω. –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —É GPT...")

    prompt = f"""
–ù–∏–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω—ã–π git patch. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏ –µ–≥–æ –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ unified diff. –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ patch:
{content[:3000]}
"""

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "–¢—ã ‚Äî AI-–ø–∞—Ç—á–µ—Ä SACI. –ò—Å–ø—Ä–∞–≤–ª—è–π git-patch."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
        max_tokens=1000,
    )

    return response.choices[0].message.content.strip()


def send_to_telegram(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": text}
    response = requests.post(url, data=payload)
    if response.status_code == 200:
        print("üì¨ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram.")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ Telegram: {response.status_code} {response.text}")


def run_refactor():
    print("üîÑ –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–¥–æ–≤—É—é –±–∞–∑—É –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º...")
    subprocess.run(["python", "saci_remote_agent.py"])

    print("üß† GPT-–∞–Ω–∞–ª–∏–∑ —á–∞–Ω–∫–æ–≤ –∫–æ–¥–∞...")
    chunks = load_chunks()
    if not chunks:
        send_to_telegram("‚ö†Ô∏è –ù–µ—Ç —á–∞–Ω–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        return

    patch = request_gpt_patch(chunks)
    if not patch:
        print("‚ö†Ô∏è GPT –Ω–µ –≤–µ—Ä–Ω—É–ª –ø–∞—Ç—á.")
        return

    patch_text = request_gpt_patch(chunks)
    if not is_patch_valid(patch_text):
        patch_text = repair_patch_with_gpt(patch_text)
        print("‚úÖ –ü–∞—Ç—á –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω GPT.")

    filename, path = save_patch(patch_text)

    send_patch_with_buttons(filename)


if __name__ == "__main__":
    import sys

    if "multi" in sys.argv:
        run_multi_pass_refactor()
    else:
        run_refactor()
