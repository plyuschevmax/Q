import os
import json
import openai
import requests
from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton
from datetime import datetime
from dotenv import load_dotenv
import subprocess  # –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ remote_agent / splitter
from agents.file_splitter import split_all_py_files  # –µ—Å–ª–∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π split –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
import sys
import os
sys.path.append(os.path.abspath("."))


load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

openai.api_key = OPENAI_API_KEY

FILE_MAP_PATH = "logs/saci_file_map.json"
PATCH_DIR = "patches"

CHUNKS_PATH = "logs/saci_code_chunks.json"

def generate_all_reviews_markdown(patch_name):
    agents = {
        "architect": "üß† Architect",
        "developer": "üë®‚Äçüíª Developer",
        "tester": "üß™ Tester",
        "strategist": "üéØ Strategist"
    }

    md = f"# üîç Patch Review ‚Äî `{patch_name}`\n\n---\n"

    for agent_key, emoji_title in agents.items():
        review = generate_patch_review(patch_name, agent_key)
        md += f"\n## {emoji_title}\n\n{review}\n\n---\n"

    os.makedirs("logs/patch_reviews", exist_ok=True)
    path = f"logs/patch_reviews/{patch_name}.md"
    with open(path, "w", encoding="utf-8") as f:
        f.write(md)

    return path

def send_review_markdown_to_telegram(patch_name):
    path = f"logs/patch_reviews/{patch_name}.md"
    if not os.path.exists(path):
        return

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendDocument"
    with open(path, "rb") as doc:
        files = {"document": doc}
        data = {
            "chat_id": CHAT_ID,
            "caption": f"üìÑ –û–±—â–µ–µ —Ä–µ–≤—å—é –æ—Ç –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–æ–≤ –ø–æ `{patch_name}`",
            "parse_mode": "Markdown"
        }
        requests.post(url, files=files, data=data)

def generate_patch_review(patch_name, agent="architect"):
    patch_path = None
    for ext in [".patch", ".diff"]:
        path = f"patches/{patch_name}{ext}"
        if os.path.exists(path):
            patch_path = path
            break

    if not patch_path:
        return "‚ùå Patch –Ω–µ –Ω–∞–π–¥–µ–Ω."

    with open(patch_path, "r", encoding="utf-8") as f:
        patch_text = f.read()

    persona = {
        "architect": "–¢—ã ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π AI, –æ—Ü–µ–Ω–∏–≤–∞–µ—à—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏.",
        "developer": "–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π Python-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ SACI.",
        "tester": "–¢—ã ‚Äî AI-—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫, –∏—â–µ—à—å —Å–ª–∞–±—ã–µ –º–µ—Å—Ç–∞.",
        "strategist": "–¢—ã ‚Äî AI-—Å—Ç—Ä–∞—Ç–µ–≥, —Å–º–æ—Ç—Ä–∏—à—å –Ω–∞ –ø–æ–ª—å–∑—É –≤ –±—É–¥—É—â–µ–º."
    }.get(agent, "–¢—ã ‚Äî AI-–ø–æ–º–æ—â–Ω–∏–∫.")

    prompt = f"""
{persona}
–î–∞–π —Ä–µ–≤—å—é –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π patch (diff):
- –ß—Ç–æ —É–ª—É—á—à–∞–µ—Ç?
- –ö–∞–∫–∏–µ –ø–ª—é—Å—ã?
- –ï—Å—Ç—å –ª–∏ —Ä–∏—Å–∫–∏?
{patch_text[:3000]}
"""

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": persona},
            {"role": "user", "content": prompt}
        ],
        temperature=0.4,
        max_tokens=400
    )

    return response['choices'][0]['message']['content'].strip()

def generate_all_patch_reviews(patch_name):
    agents = ["architect", "developer", "tester", "strategist"]
    results = {}
    for agent in agents:
        review = generate_patch_review(patch_name, agent)
        results[agent] = review
    return results

def send_patch_with_reviews(filename):
    base = filename.replace(".patch", "").replace(".diff", "")
    reviews = generate_all_patch_reviews(base)

    markup = InlineKeyboardMarkup(row_width=2)
    markup.add(
        InlineKeyboardButton("üìÑ –ü—Ä–æ—Å–º–æ—Ç—Ä patch", callback_data=f"review:{base}"),
        InlineKeyboardButton("‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å", callback_data=f"apply:{base}"),
    )
    markup.row(
        InlineKeyboardButton("üß† Architect", callback_data=f"view_rev:{base}:architect"),
        InlineKeyboardButton("üë®‚Äçüíª Developer", callback_data=f"view_rev:{base}:developer"),
        InlineKeyboardButton("üß™ Tester", callback_data=f"view_rev:{base}:tester"),
        InlineKeyboardButton("üéØ Strategist", callback_data=f"view_rev:{base}:strategist"),
    )

    review_text = "\n".join([
        f"*{agent.title()}*:\n{review[:200]}" for agent, review in reviews.items()
    ])

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": f"üì¶ GPT-–ø–∞—Ç—á `{filename}`\n\nüß† –†–µ–≤—å—é –∞–≥–µ–Ω—Ç–æ–≤:\n\n{review_text}\n\n–í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∏–∂–µ:",
        "reply_markup": json.dumps(markup.to_dict()),
        "parse_mode": "Markdown"
    }
    requests.post(url, json=payload)

from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton

def send_patch_with_buttons(filename):
    base = filename.replace(".diff", "").replace(".patch", "")

    markup = InlineKeyboardMarkup(row_width=2)
    markup.add(
        InlineKeyboardButton("üìÑ –ü—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å", callback_data=f"review:{base}"),
        InlineKeyboardButton("‚úÖ –ü—Ä–∏–º–µ–Ω–∏—Ç—å", callback_data=f"apply:{base}"),
        InlineKeyboardButton("üß† Architect", callback_data=f"review_agent:{base}:architect"),
        InlineKeyboardButton("üë®‚Äçüíª Developer", callback_data=f"review_agent:{base}:developer"),
        InlineKeyboardButton("üéØ Strategist", callback_data=f"review_agent:{base}:strategist")
    )

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": f"üì¶ GPT –ø—Ä–µ–¥–ª–æ–∂–∏–ª –ø–∞—Ç—á: `{filename}`\n\nüìé –í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ:",
        "reply_markup": json.dumps(markup.to_dict()),
        "parse_mode": "Markdown"
    }

    requests.post(url, json=payload)

def load_chunks():
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî Tree-sitter
    tree_chunks_path = "logs/saci_code_chunks.json"
    if os.path.exists(tree_chunks_path):
        with open(tree_chunks_path, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        print("‚ö†Ô∏è –ß–∞–Ω–∫–∏ Tree-sitter –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞—Ä—ã–π split.")
        with open("logs/saci_file_map.json", "r", encoding="utf-8") as f:
            file_map = json.load(f)
        return split_all_py_files(file_map)  # ‚Üê –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏—è-—Ä–µ–∑–µ—Ä–≤

def generate_patch_prompt(file_map):
    file_bundle = "\n\n".join([
        f"### {fname}\n```python\n{content[:1500]}\n```"
        for fname, content in file_map.items()
        if fname.endswith(".py")
    ])
    return f"""
–¢—ã ‚Äî AI-–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä SACI. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ unified diff (git diff).

–¢–æ–ª—å–∫–æ –æ–¥–∏–Ω diff-—Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏. –í–Ω–∏–∑—É ‚Äî –∫—Ä–∞—Ç–∫–∏–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è (1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). –ù–∏–∫–∞–∫–∏—Ö –ª–∏—à–Ω–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.

–í–æ—Ç –∫–æ–¥:
{file_bundle}
"""

def request_gpt_patch(chunks):
    prompt = "–¢—ã ‚Äî AI-–∫–æ–¥-–∏–Ω–∂–µ–Ω–µ—Ä SACI. –ù–∏–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏ –∫–æ–¥–∞ (—á–∞–Ω–∫–∏). –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏—Ö –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ unified diff:\n\n"

    selected_chunks = sorted(chunks.items(), key=lambda x: priority_sort(x[0]))
    total_chars = 0
    max_chars = 8000
    included = 0

    for name, content in selected_chunks:
        sliced = content[:2000]
        chunk_text = f"### {name} ###\n```\n{sliced}\n```\n\n"
        if total_chars + len(chunk_text) > max_chars:
            break
        prompt += chunk_text
        total_chars += len(chunk_text)
        included += 1

    prompt += "\n–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —É–ª—É—á—à–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ unified diff (.diff). –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π ‚Äî —Ç–æ–ª—å–∫–æ patch."

    print(f"üìä –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {included} / {len(chunks)}")

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "–¢—ã ‚Äî AI-–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä SACI. –í–æ–∑–≤—Ä–∞—â–∞–π patch-–∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ unified diff."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=1200
    )

    return response.choices[0].message.content.strip()

def priority_sort(name):
    if "goal_runner" in name: return 1
    if "developer" in name: return 2
    if "tester" in name: return 3
    if "core/" in name: return 4
    return 99

def save_patch(content):
    os.makedirs(PATCH_DIR, exist_ok=True)
    ts = datetime.now().strftime("%Y-%m-%d_%H-%M")
    filename = f"auto_gpt_patch_{ts}.diff"
    path = os.path.join(PATCH_DIR, filename)
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return filename, path

def is_patch_valid(content):
    return content.startswith("diff --git") and "@@" in content and "--- " in content

def repair_patch_with_gpt(content):
    print("üîß –ü–∞—Ç—á –ø–æ–≤—Ä–µ–∂–¥—ë–Ω. –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —É GPT...")

    prompt = f"""
–ù–∏–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ–≤—Ä–µ–∂–¥—ë–Ω–Ω—ã–π –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω—ã–π git patch. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏ –µ–≥–æ –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ unified diff. –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ patch:
{content[:3000]}
"""

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "–¢—ã ‚Äî AI-–ø–∞—Ç—á–µ—Ä SACI. –ò—Å–ø—Ä–∞–≤–ª—è–π git-patch."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=1000
    )

    return response.choices[0].message.content.strip()

def send_to_telegram(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": text}
    response = requests.post(url, data=payload)
    if response.status_code == 200:
        print("üì¨ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram.")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ Telegram: {response.status_code} {response.text}")

def run_refactor():
    print("üîÑ –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–¥–æ–≤—É—é –±–∞–∑—É –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º...")
    subprocess.run(["python", "saci_remote_agent.py"])
    subprocess.run(["python", "agents/file_splitter.py"])
    
    print("üß† GPT-–∞–Ω–∞–ª–∏–∑ —á–∞–Ω–∫–æ–≤ –∫–æ–¥–∞...")
    chunks = load_chunks()
    if not chunks:
        send_to_telegram("‚ö†Ô∏è –ù–µ—Ç —á–∞–Ω–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        return

    patch = request_gpt_patch(chunks)
    if not patch:
        print("‚ö†Ô∏è GPT –Ω–µ –≤–µ—Ä–Ω—É–ª –ø–∞—Ç—á.")
        return

    patch_text = request_gpt_patch(chunks)
    if not is_patch_valid(patch_text):
        patch_text = repair_patch_with_gpt(patch_text)
        print("‚úÖ –ü–∞—Ç—á –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω GPT.")

    filename, path = save_patch(patch_text)
    
    send_patch_with_buttons(filename)

if __name__ == "__main__":
    run_refactor()

